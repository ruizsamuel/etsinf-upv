{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística aplicada a iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lectura del corpus y partición:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris(); X = iris.data.astype(np.float16); y = iris.target.astype(np.uint)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LogisticRegression:** $\\;$ implementación de regresión logística en sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de test: 0.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = LogisticRegression(random_state=23).fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "print(f\"Error de test: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warnings:** $\\;$ sklearn es un poco \"insistente\" con los warnings; ignoraremos los avisos sobre convergencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solvers:** $\\;$ el parámetro `solver` de LogisticRegression permite elegir entre diferentes solvers (algoritmos de optimitzación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de test después de entrenar con el solver lbfgs: 0.0%\n",
      "Error de test después de entrenar con el solver liblinear: 3.3%\n",
      "Error de test después de entrenar con el solver newton-cg: 0.0%\n",
      "Error de test después de entrenar con el solver newton-cholesky: 3.3%\n",
      "Error de test después de entrenar con el solver sag: 0.0%\n",
      "Error de test después de entrenar con el solver saga: 0.0%\n"
     ]
    }
   ],
   "source": [
    "for solver in ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']:\n",
    "    clf = LogisticRegression(random_state=23, solver=solver, max_iter=10000).fit(X_train, y_train)\n",
    "    err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "    print(f\"Error de test después de entrenar con el solver {solver!s}: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tolerancia:** $\\;$ el parámetro `tol` establece un umbral de tolerancia para acabar el entrenamiento (1e4 por defecto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de test con tolerancia 0.0001: 0.0%\n",
      "Error de test con tolerancia 0.01: 3.3%\n",
      "Error de test con tolerancia 1: 60.0%\n",
      "Error de test con tolerancia 100.0: 60.0%\n",
      "Error de test con tolerancia 10000.0: 60.0%\n"
     ]
    }
   ],
   "source": [
    "for tol in (1e-4, 1e-2, 1, 1e2, 1e4):\n",
    "    clf = LogisticRegression(tol=tol, random_state=23, max_iter=10000).fit(X_train, y_train)\n",
    "    err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "    print(f\"Error de test con tolerancia {tol}: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regularización:** $\\;$ el parámetro `C` (positivo, $1.0$ por defecto) des-regulariza el criterio de entrenamiento\n",
    "* **Posibilidad de subajuste:** $\\;$ con un valor próximo a cero (máxima regularización)\n",
    "* **Posibilidad de sobreajuste:** $\\;$ con un valor positivo muy alto (mínima regularización)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de test con C 0.01: 6.7%\n",
      "Error de test con C 0.1: 3.3%\n",
      "Error de test con C 1: 0.0%\n",
      "Error de test con C 10: 3.3%\n",
      "Error de test con C 100: 3.3%\n"
     ]
    }
   ],
   "source": [
    "for C in (1e-2, 1e-1, 1, 1e1, 1e2):\n",
    "    clf = LogisticRegression(C=C, random_state=23, max_iter=10000).fit(X_train, y_train)\n",
    "    err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "    print(f\"Error de test con C {C:g}: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Early stopping:** $\\;$ ahorramos cálculo y evitamos sobre-entrenamiento (\"regularizamos\") acabando pronto (en pocas iteraciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de test con max_iter 10: 0.0%\n",
      "Error de test con max_iter 20: 3.3%\n",
      "Error de test con max_iter 50: 0.0%\n",
      "Error de test con max_iter 100: 0.0%\n"
     ]
    }
   ],
   "source": [
    "for max_iter in (10, 20, 50, 100):\n",
    "    clf = LogisticRegression(random_state=23, max_iter=max_iter).fit(X_train, y_train)\n",
    "    err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "    print(f\"Error de test con max_iter {max_iter}: {err_test:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
